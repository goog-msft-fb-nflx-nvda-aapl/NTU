{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1. Linear Discriminant Function (PAGE 08)\n",
    "\n",
    "We aim to prove why the \"Linear Discriminant Function\" is given by  \n",
    "$\n",
    "\\delta_k(x) = \\frac{x \\mu_k}{\\sigma^2} - \\frac{\\mu_k^2}{2\\sigma^2} + \\ln(\\pi_k).\n",
    "$\n",
    "Using the hint:  \n",
    "$\n",
    "\\ln \\left( \\Pr(Y = k \\mid X = x) \\right) \\approx \\delta_k(x).\n",
    "$\n",
    "\n",
    "## Step-by-Step Derivation\n",
    "\n",
    "### 1. Bayes’ Theorem  \n",
    "Using Bayes' Theorem, the posterior probability of class $ Y = k $ is:  \n",
    "$\n",
    "\\Pr(Y = k \\mid X = x) = \\frac{f_k(x) \\cdot \\pi_k}{\\sum_{j=1}^K f_j(x) \\cdot \\pi_j},\n",
    "$\n",
    "where  \n",
    "- $ f_k(x) $: class-conditional density function (assumed to be normal),  \n",
    "- $ \\pi_k $: prior probability of class $ k $,  \n",
    "- $ K $: total number of classes.\n",
    "\n",
    "### 2. Normal (Gaussian) Density Function for $ f_k(x) $  \n",
    "Since $ f_k(x) $ follows a normal distribution:  \n",
    "$\n",
    "f_k(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left( - \\frac{(x - \\mu_k)^2}{2 \\sigma^2} \\right),\n",
    "$\n",
    "where $ \\mu_k $ is the mean and $ \\sigma^2 $ is the (common) variance.\n",
    "\n",
    "### 3. Logarithm of Posterior Probability (Approximation)  \n",
    "Take the natural logarithm of both sides:  \n",
    "$\n",
    "\\ln \\left( \\Pr(Y = k \\mid X = x) \\right) = \\ln \\left( \\frac{f_k(x) \\cdot \\pi_k}{\\sum_{j=1}^K f_j(x) \\cdot \\pi_j} \\right).\n",
    "$\n",
    "Since we are only interested in the discriminant function and not the exact posterior, we focus on the numerator:  \n",
    "$\n",
    "\\ln \\left( f_k(x) \\cdot \\pi_k \\right) = \\ln(f_k(x)) + \\ln(\\pi_k).\n",
    "$\n",
    "\n",
    "### 4. Simplify $ \\ln(f_k(x)) $  \n",
    "Substitute the normal density function $ f_k(x) $:  \n",
    "$\n",
    "\\ln(f_k(x)) = \\ln \\left( \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left( - \\frac{(x - \\mu_k)^2}{2 \\sigma^2} \\right) \\right).\n",
    "$\n",
    "Break this into separate terms:  \n",
    "$\n",
    "\\ln(f_k(x)) = - \\frac{1}{2} \\ln(2 \\pi \\sigma^2) - \\frac{(x - \\mu_k)^2}{2 \\sigma^2}.\n",
    "$\n",
    "\n",
    "### 5. Expand $ (x - \\mu_k)^2 $  \n",
    "Expand the quadratic term:  \n",
    "$\n",
    "(x - \\mu_k)^2 = x^2 - 2x \\mu_k + \\mu_k^2.\n",
    "$\n",
    "Thus,  \n",
    "$\n",
    "\\ln(f_k(x)) = - \\frac{1}{2} \\ln(2 \\pi \\sigma^2) - \\frac{x^2 - 2x \\mu_k + \\mu_k^2}{2 \\sigma^2}.\n",
    "$\n",
    "\n",
    "### 6. Simplify the Expression  \n",
    "Drop constants that do not depend on $ k $, as they will cancel out when comparing different classes. This leaves:  \n",
    "$\n",
    "\\ln(f_k(x)) \\approx - \\frac{x^2}{2 \\sigma^2} + \\frac{x \\mu_k}{\\sigma^2} - \\frac{\\mu_k^2}{2 \\sigma^2}.\n",
    "$\n",
    "Now, include the term $ \\ln(\\pi_k) $:  \n",
    "$\n",
    "\\ln \\left( f_k(x) \\cdot \\pi_k \\right) \\approx \\frac{x \\mu_k}{\\sigma^2} - \\frac{\\mu_k^2}{2 \\sigma^2} + \\ln(\\pi_k).\n",
    "$\n",
    "\n",
    "### 7. Define the Linear Discriminant Function  \n",
    "Let $ \\delta_k(x) $ represent the discriminant function:  \n",
    "$\n",
    "\\delta_k(x) = \\frac{x \\mu_k}{\\sigma^2} - \\frac{\\mu_k^2}{2 \\sigma^2} + \\ln(\\pi_k).\n",
    "$\n",
    "\n",
    "### Conclusion  \n",
    "We have derived the linear discriminant function $ \\delta_k(x) $, which depends linearly on $ x $ and differentiates between classes based on their means $ \\mu_k $, prior probabilities $ \\pi_k $, and the common variance $ \\sigma^2 $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2. Compare Two Clas (PAGE 09)\n",
    "\n",
    "### 1. Discriminant Functions for Two Categories $ k $ and $ i $\n",
    "From Linear Discriminant Analysis (LDA), we have derived in Question 1 of Homework 5 that the discriminant function for a given category $ k $ is:  \n",
    "$\n",
    "\\delta_k(x) = \\frac{x \\mu_k}{\\sigma^2} - \\frac{\\mu_k^2}{2 \\sigma^2} + \\ln(\\pi_k),\n",
    "$\n",
    "and for category $ i $, it is:  \n",
    "$\n",
    "\\delta_i(x) = \\frac{x \\mu_i}{\\sigma^2} - \\frac{\\mu_i^2}{2 \\sigma^2} + \\ln(\\pi_i).\n",
    "$\n",
    "\n",
    "### 2. Comparing $ \\delta_k(x) $ and $ \\delta_i(x) $\n",
    "We assign $ x $ to category $ k $ if $ \\delta_k(x) > \\delta_i(x) $.  \n",
    "Thus, we compare the two discriminant functions:  $ \\delta_k(x) > \\delta_i(x).$    \n",
    "This inequality becomes:  $\\frac{x \\mu_k}{\\sigma^2} - \\frac{\\mu_k^2}{2 \\sigma^2} + \\ln(\\pi_k) > \\frac{x \\mu_i}{\\sigma^2} - \\frac{\\mu_i^2}{2 \\sigma^2} + \\ln(\\pi_i).$　　\n",
    "\n",
    "### 3. Simplifying the Inequality\n",
    "Rearrange the terms:  $\\frac{x \\mu_k}{\\sigma^2} - \\frac{x \\mu_i}{\\sigma^2} > \\frac{\\mu_k^2}{2 \\sigma^2} - \\frac{\\mu_i^2}{2 \\sigma^2} + \\ln(\\pi_i) - \\ln(\\pi_k).$  \n",
    "Factor out common terms:  $\\frac{x (\\mu_k - \\mu_i)}{\\sigma^2} > \\frac{\\mu_k^2 - \\mu_i^2}{2 \\sigma^2} + \\ln\\left( \\frac{\\pi_i}{\\pi_k} \\right).$  \n",
    "Multiply both sides by $ \\sigma^2 $ (since $ \\sigma^2 > 0 $,  this doesn't change the inequality):  $x (\\mu_k - \\mu_i) > \\frac{\\mu_k^2 - \\mu_i^2}{2} + \\sigma^2 \\ln\\left( \\frac{\\pi_i}{\\pi_k} \\right).$　　\n",
    "\n",
    "### 4. Case 1: Equal Priors ( $ \\pi_k = \\pi_i $ )   <--- Assumption in the LectureSlide.\n",
    "If $ \\pi_k = \\pi_i $, then $ \\ln\\left( \\frac{\\pi_i}{\\pi_k} \\right) = 0 $, and the inequality simplifies to:  　$x (\\mu_k - \\mu_i) > \\frac{\\mu_k^2 - \\mu_i^2}{2}.$  \n",
    "Multiply both sides by 2 to remove the fraction:  $2x (\\mu_k - \\mu_i) > \\mu_k^2 - \\mu_i^2.$  \n",
    "Thus, if this inequality holds, assign $ x $ to category $ k $. Otherwise, assign $ x $ to category $ i $.  \n",
    "This gives us the two cases:\n",
    "- **If $ 2x (\\mu_k - \\mu_i) > \\mu_k^2 - \\mu_i^2 $**, assign $ x $ to group $ k $.  \n",
    "- **If $ 2x (\\mu_k - \\mu_i) < \\mu_k^2 - \\mu_i^2 $**, assign $ x $ to group $ i $.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Case 2: Unequal Priors ( $ \\pi_k \\neq \\pi_i $ )  \n",
    "If the prior probabilities $ \\pi_k $ and $ \\pi_i $ are not equal, we cannot drop the $ \\ln\\left( \\frac{\\pi_i}{\\pi_k} \\right) $ term.  \n",
    "Thus, the inequality becomes:  $2x (\\mu_k - \\mu_i) > \\mu_k^2 - \\mu_i^2 + 2 \\sigma^2 \\ln\\left( \\frac{\\pi_i}{\\pi_k} \\right).$\n",
    "If this inequality holds, assign $ x $ to category $ k $; otherwise, assign $ x $ to category $ i $.  \n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion  \n",
    "\n",
    "The derived formula allows us to compare the two groups based on their means $ \\mu_k $, $ \\mu_i $, and their priors $ \\pi_k $, $ \\pi_i $. In simple terms:\n",
    "- The left-hand side $ 2x (\\mu_k - \\mu_i) $ represents how far $ x $ is from the midpoint of the two means.  \n",
    "- The right-hand side $ \\mu_k^2 - \\mu_i^2 + 2 \\sigma^2 \\ln\\left( \\frac{\\pi_i}{\\pi_k} \\right) $ represents the \"threshold\" adjusted by the class priors.\n",
    "\n",
    "Thus, this formula helps decide which category $ x $ should be assigned to based on the comparison between the observation and this threshold."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
