{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Curriculum Number: CSIE5137\n",
    "* Course Name: Web Retrieval and Mining\n",
    "* Student ID: r13921031\n",
    "* Subject: Assignment 2\n",
    "* The notebook can be accessed through this [link]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🤔 Question 1. \n",
    "How is the document frequency df of a term used to scale its weight?   \n",
    "Denoting as usual the total number of documents in a collection by N, we define \"INVERSE DOCUMENT\" the inverse document frequency (idf) of a term t as follows:  \n",
    " - (6.7) $\\text{idf}_{t} = \\log( \\frac{N}{\\text{df}_{t}} )$    \n",
    "Thus the idf of a rare term is high, whereas the idf of a frequent term is likely to be low.  \n",
    "\n",
    "#### Tf-idf weighting\n",
    "We now combine the definitions of term frequency and inverse document frequency, to produce a composite weight for each term in each document.\n",
    "The tf-idf weighting scheme assigns to term t a weight in document d given by  \n",
    " - (6.8) $\\text{tf-idf}_{t,d} = \\text{tf}_{t,d} \\times \\text{idf}_{t} $   \n",
    "\n",
    "In other words, tf-idft,d assigns to term t a weight in document d that is\n",
    "1. highest when t occurs many times within a small number of documents (thus lending high discriminating power to those documents);\n",
    "2. lower when the term occurs fewer times in a document, or occurs in many documents (thus offering a less pronounced relevance signal);\n",
    "3. lowest when the term occurs in virtually all documents.  \n",
    "\n",
    "DOCUMENT VECTOR At this point, we may view each document as a vector with one component corresponding to each term in the dictionary, together with a weight for each component that is given by (6.8).   \n",
    "For dictionary terms that do not occur in a document, this weight is zero.   \n",
    "This vector form will prove to be crucial to scoring and ranking.  \n",
    "As a first step, we introduce the overlap score measure: the score of a document d is the sum, over all query terms, of the number of times each of the query terms occurs in d.   \n",
    "We can refine this idea so that we add up not the number of  occurrences of each query term t in d, but instead the tf-idf weight of each term in d.\n",
    " - (6.9) $Score(q,d) = \\sum_{ t \\in q} { \\text{tf-idf}_{t,d}}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✅ 1-1. How does the base of the logarithm in (6.7) affect the score calculation in (6.9)?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of the Logarithm Base on Score Calculation  \n",
    "\n",
    "The base of the logarithm in the inverse document frequency (idf) formula:  \n",
    "\n",
    "$\n",
    "\\text{idf}_t = \\log_b \\left( \\frac{N}{\\text{df}_t} \\right)\n",
    "$\n",
    "\n",
    "affects the weight assigned to terms and, consequently, the **score** of a document given by:\n",
    "\n",
    "$\n",
    "Score(q,d) = \\sum_{t \\in q} \\text{tf-idf}_{t,d}\n",
    "$\n",
    "\n",
    "where $\\text{tf-idf}_{t,d} = \\text{tf}_{t,d} \\times \\text{idf}_t$.\n",
    "\n",
    "#### **1. Effect on Score Magnitude**  \n",
    "Changing the base of the logarithm affects the absolute values of idf and thus the score $ Score(q,d) $.   \n",
    "Specifically, if we switch from base $ b_1 $ to base $ b_2 $, we use the logarithmic identity:\n",
    "\n",
    "$\n",
    "\\log_{b_2}(x) = \\frac{\\log_{b_1}(x)}{\\log_{b_1}(b_2)}\n",
    "$\n",
    "\n",
    "\n",
    "This means that changing the logarithm base effectively **scales all idf values** by a constant factor. Therefore, the final document scores will also be **scaled by the same constant factor**.\n",
    "\n",
    "\n",
    "For example, if we switch from natural logarithm ($\\ln$, base $ e $) to base 10:\n",
    "\n",
    "$\n",
    "\\log_{10} x = \\frac{\\ln x}{\\ln 10} \\approx 0.4343 \\ln x\n",
    "$\n",
    "\n",
    "So, all scores computed using base 10 would be about **43% of the scores computed using natural logarithm**, but the ranking order remains the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在計算文檔權重時，對數基數的選擇（公式6.7）會影響最終tf-idf分數的計算（公式6.9），但不會改變文檔的相對排名。\n",
    "\n",
    "在逆向文檔頻率(idf)公式中：\n",
    "$\\text{idf}_{t} = \\log(\\frac{N}{\\text{df}_{t}})$\n",
    "\n",
    "改變對數的基數會對idf值產生標量效應：\n",
    "- 如果使用自然對數（基數e），idf值會相對較小\n",
    "- 如果使用基數10的對數，idf值會相對較大\n",
    "- 如果使用基數2的對數，則對應於「每次文檔頻率減半，增加一個固定權重」的語義\n",
    "\n",
    "這個標量效應會直接影響公式6.9的分數計算：\n",
    "$Score(q,d) = \\sum_{t \\in q}{\\text{tf-idf}_{t,d}}$\n",
    "\n",
    "因為tf-idf是tf與idf的乘積，所以對數基數的選擇會影響每個查詢詞對最終分數的貢獻程度。然而，由於這種影響是整個系統中一致的標量變化，它不會改變文檔之間的相對排名。換句話說，無論選擇哪種對數基數，如果文檔A的分數高於文檔B，在更改對數基數後，A仍然會排在B之前。\n",
    "\n",
    "在實踐中，對數基數的選擇通常取決於系統設計和實際應用需求，沒有絕對的「最佳」基數。\n",
    "\n",
    "$\n",
    "\\text{idf}_t = \\log_b \\left( \\frac{N}{\\text{df}_t} \\right) = \\frac{\\log_{10} \\left( \\frac{N}{\\text{df}_t} \\right)}{\\log_{10} \\left( b \\right)}\n",
    "$  \n",
    "🗣️結論：更改底数從10為b, 会使分数乘以一个因子 $\\frac{1}{\\log_{10}(b)}$，但给定查询下两个文档的相对分数不受影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✅ 1-2. How does the base of the logarithm affect the relative scores of two documents on a given query?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Effect on Relative Scores of Two Documents**  \n",
    "Since all idf values (and hence tf-idf weights) are scaled **proportionally**, the relative ranking of two documents remains unchanged. That is:\n",
    "\n",
    "- If $ Score(q, d_1) > Score(q, d_2) $ using one base, the same inequality holds for any other logarithm base.\n",
    "- The **relative differences** between document scores remain consistent across different logarithm bases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Conclusion**  \n",
    "- The choice of the logarithm base affects the absolute magnitude of document scores but **not the ranking** of documents.\n",
    "- In practice, bases such as 2, 10, or $ e $ are commonly used, but they do not impact the effectiveness of ranking, only the scale of scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "對數基數在idf計算中（公式6.7）不會影響兩個文檔對於給定查詢的相對分數。\n",
    "\n",
    "當比較兩個文檔d₁和d₂對於同一查詢q的分數時：\n",
    "\n",
    "對於文檔d₁：\n",
    "$Score(q,d₁) = \\sum_{t \\in q}{\\text{tf}_{t,d₁} \\times \\log_b(\\frac{N}{\\text{df}_{t}})}$\n",
    "\n",
    "對於文檔d₂：\n",
    "$Score(q,d₂) = \\sum_{t \\in q}{\\text{tf}_{t,d₂} \\times \\log_b(\\frac{N}{\\text{df}_{t}})}$\n",
    "\n",
    "如果我們將對數基數從b更改為另一個基數b'，這相當於將所有idf值乘以一個常數因子（log_b'(x) = log_b(x) × log_b'(b)）：\n",
    "\n",
    "$\\log_{b'}(\\frac{N}{\\text{df}_{t}}) = \\log_b(\\frac{N}{\\text{df}_{t}}) \\times \\log_{b'}(b)$\n",
    "\n",
    "由於這個常數因子log_{b'}(b)平等地應用於所有文檔中的所有詞項，它實際上是將所有文檔分數按相同的常數進行縮放：\n",
    "\n",
    "$Score'(q,d) = Score(q,d) \\times \\log_{b'}(b)$\n",
    "\n",
    "因此，如果使用基數b時Score(q,d₁) > Score(q,d₂)，那麼：\n",
    "$Score'(q,d₁) = Score(q,d₁) \\times \\log_{b'}(b) > Score(q,d₂) \\times \\log_{b'}(b) = Score'(q,d₂)$\n",
    "\n",
    "無論選擇何種對數基數，文檔的相對排名都保持不變。這就是為什麼在實踐中，不同的信息檢索系統可能使用不同的對數基數（例如，自然對數、基數2的對數或基數10的對數）而不影響文檔排名結果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🤔 Question 2. SVD(singular value decomposition)\n",
    "Let C be the term-document incidence matrix for a collection.  \n",
    "The number of linearly independent rows in C is 2 ==> rank(C) = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given matrix C\n",
    "C = np.array([[1, 1],\n",
    "              [0, 1],\n",
    "              [1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the SVD of the matrix C is U * Σ * V^T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given SVD components\n",
    "U = np.array([[-0.816, 0.000],\n",
    "              [-0.408, -0.707],\n",
    "              [-0.408, 0.707]])\n",
    "\n",
    "Sigma = np.array([[1.732, 0.000],\n",
    "                  [0.000, 1.000]])\n",
    "\n",
    "VT = np.array([[-0.707, -0.707],\n",
    "               [ 0.707, -0.707]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute C * C^T and C^T * C\n",
    "CCT = C @ C.T\n",
    "CTC = C.T @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First column:\n",
      " [-0.816 -0.408 -0.408]\n",
      "\n",
      "Second column:\n",
      " [ 0.    -0.707  0.707]\n",
      "CCT * u_col_1:\n",
      " [-2.448 -1.224 -1.224]\n",
      "Eigenvalue 1: 3.0\n",
      "\n",
      "CCT * u_col_2:\n",
      " [ 0.    -0.707  0.707]\n",
      "Eigenvalue 2: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Extract the first column\n",
    "u_col_1 = U[:, 0]\n",
    "print(\"First column:\\n\", u_col_1)\n",
    "\n",
    "# Extract the second column\n",
    "u_col_2 = U[:, 1]\n",
    "print(\"\\nSecond column:\\n\", u_col_2)\n",
    "\n",
    "result_1 = np.dot(CCT, u_col_1)\n",
    "print(\"CCT * u_col_1:\\n\", result_1)\n",
    "\n",
    "#calculating the eigenvalue.\n",
    "eigenvalue_1 = result_1[0] / u_col_1[0]\n",
    "print(\"Eigenvalue 1:\", eigenvalue_1)\n",
    "\n",
    "print()\n",
    "result_2 = np.dot(CCT, u_col_2)\n",
    "print(\"CCT * u_col_2:\\n\", result_2)\n",
    "\n",
    "eigenvalue_2 = result_2[1] / u_col_2[1]\n",
    "print(\"Eigenvalue 2:\", eigenvalue_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column Name | Values                 | CCT * Column | Eigenvalue |\n",
    "|-------------|------------------------|--------------|------------|\n",
    "| First Column | [-0.816 -0.408 -0.408] | [-2.448 -1.224 -1.224] | 3.0        |\n",
    "| Second Column| [ 0.    -0.707  0.707] | [ 0.    -0.707  0.707] | 1.0        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 驗證投影片 vsmodel_2025 第 60 頁的結果\n",
    "From the python code we can see that \n",
    " - the 1st column of U are orthogonal eigenvector corresponding to the eigenvalue 3.0 of C * C^T \n",
    " - the 2nd column of U are orthogonal eigenvector corresponding to the eigenvalue 1.0 of C * C^T \n",
    "```python\n",
    "CCT  = array([  [2, 1, 1],\n",
    "                [1, 1, 0],\n",
    "                [1, 0, 1]])\n",
    "```\n",
    "```python\n",
    "u_col_1 = np.array([[-0.816],\n",
    "                    [-0.408],\n",
    "                    [-0.408]]) \n",
    "u_col_2 = np.array([ [0.000],\n",
    "                    [-0.707],\n",
    "                     [0.707]]) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First column of V:\n",
      " [-0.707 -0.707]\n",
      "\n",
      "Second column of V:\n",
      " [ 0.707 -0.707]\n",
      "\n",
      "CTC * v_col_1:\n",
      " [-2.121 -2.121]\n",
      "\n",
      "CTC * v_col_2:\n",
      " [ 0.707 -0.707]\n",
      "\n",
      "Eigenvalue 1: 3.0\n",
      "Eigenvalue 2: 1.0\n",
      "\n",
      "| Column Name | Values                 | CTC * Column | Eigenvalue |\n",
      "|-------------|------------------------|--------------|------------|\n",
      "| First Column | [-0.707 -0.707] | [-2.121 -2.121] | 3.0 |\n",
      "| Second Column| [ 0.707 -0.707] | [ 0.707 -0.707] | 1.0 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# V is the matrix of eigenvectors (columns are eigenvectors)\n",
    "V = VT.T  # Transpose VT to get V\n",
    "\n",
    "# Extract columns from V\n",
    "v_col_1 = V[:, 0]\n",
    "v_col_2 = V[:, 1]\n",
    "\n",
    "print(\"First column of V:\\n\", v_col_1)\n",
    "print(\"\\nSecond column of V:\\n\", v_col_2)\n",
    "\n",
    "# Calculate CTC * v_col_1 and CTC * v_col_2\n",
    "result_1 = np.dot(CTC, v_col_1)\n",
    "result_2 = np.dot(CTC, v_col_2)\n",
    "\n",
    "print(\"\\nCTC * v_col_1:\\n\", result_1)\n",
    "print(\"\\nCTC * v_col_2:\\n\", result_2)\n",
    "\n",
    "# Calculate eigenvalues (should match np.linalg.eig)\n",
    "eigenvalue_1 = result_1[0] / v_col_1[0]\n",
    "eigenvalue_2 = result_2[0] / v_col_2[0]\n",
    "\n",
    "print(\"\\nEigenvalue 1:\", eigenvalue_1)\n",
    "print(\"Eigenvalue 2:\", eigenvalue_2)\n",
    "\n",
    "# Create markdown table\n",
    "markdown_table = \"\"\"\n",
    "| Column Name | Values                 | CTC * Column | Eigenvalue |\n",
    "|-------------|------------------------|--------------|------------|\n",
    "| First Column | {} | {} | {} |\n",
    "| Second Column| {} | {} | {} |\n",
    "\"\"\".format(v_col_1, result_1, eigenvalue_1, v_col_2, result_2, eigenvalue_2)\n",
    "\n",
    "print(markdown_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column Name | Values                 | CTC * Column | Eigenvalue |\n",
    "|-------------|------------------------|--------------|------------|\n",
    "| First Column | [-0.707 -0.707] | [-2.121 -2.121] | 3.0 |\n",
    "| Second Column| [ 0.707 -0.707] | [ 0.707 -0.707] | 1.0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 驗證投影片 vsmodel_2025 第 60 頁的結果\n",
    "From the python code we can see that \n",
    " - the 1st column of V are orthogonal eigenvector corresponding to the eigenvalue 3.0 of C^T * C \n",
    " - the 2nd column of V are orthogonal eigenvector corresponding to the eigenvalue 1.0 of C^T * C \n",
    "\n",
    "```python\n",
    "CTC  = array([  [2, 1],\n",
    "                [1, 2]])\n",
    "```\n",
    "```python\n",
    "v_col_1 = np.array([[-0.707],\n",
    "                    [-0.707]]) \n",
    "v_col_2 = np.array([ [0.707],\n",
    "                    [-0.707]]) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✅ 2-a. Show the first two largest eigenvalues of ( C * C^T ) are the same as those of ( C^T * C )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✅ 2-a-1. calculate the eigenvalues and eigenvectors of ( C * C^T )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvalues and Eigenvectors of CCT\n",
    "\n",
    "Given the matrix:\n",
    "\n",
    "```\n",
    "CCT = [[2, 1, 1],\n",
    "       [1, 1, 0],\n",
    "       [1, 0, 1]]\n",
    "```\n",
    "\n",
    "**1. Calculate Eigenvalues**\n",
    "\n",
    "The characteristic equation is `det(CCT - λI) = 0`, where `λ` are the eigenvalues and `I` is the identity matrix.\n",
    "\n",
    "$$\n",
    "CCT - \\lambda I = \\begin{bmatrix} 2 - \\lambda & 1 & 1 \\\\ 1 & 1 - \\lambda & 0 \\\\ 1 & 0 & 1 - \\lambda \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The determinant is:\n",
    "\n",
    "$$\n",
    "\\det(CCT - \\lambda I) = (2 - \\lambda)[(1 - \\lambda)^2 - 0] - 1[(1 - \\lambda) - 0] + 1[0 - (1 - \\lambda)] \\\\\n",
    "= (2 - \\lambda)(1 - 2\\lambda + \\lambda^2) - (1 - \\lambda) - (1 - \\lambda) \\\\\n",
    "= 2 - 4\\lambda + 2\\lambda^2 - \\lambda + 2\\lambda^2 - \\lambda^3 - 2 + 2\\lambda \\\\\n",
    "= -\\lambda^3 + 4\\lambda^2 - 3\\lambda \\\\\n",
    "= -\\lambda(\\lambda^2 - 4\\lambda + 3) \\\\\n",
    "= -\\lambda(\\lambda - 3)(\\lambda - 1)\n",
    "$$\n",
    "\n",
    "Setting the determinant to zero:\n",
    "\n",
    "$$\n",
    "-\\lambda(\\lambda - 3)(\\lambda - 1) = 0\n",
    "$$\n",
    "\n",
    "Thus, the eigenvalues are:\n",
    "\n",
    "$$\n",
    "\\lambda_1 = 3 \\\\\n",
    "\\lambda_2 = 1 \\\\\n",
    "\\lambda_3 = 0\n",
    "$$\n",
    "\n",
    "**2. Calculate Eigenvectors**\n",
    "\n",
    "* **For λ₁ = 3:**\n",
    "\n",
    "    Substitute λ₁ into `(CCT - λI)v = 0`:\n",
    "\n",
    "    $$\n",
    "    \\begin{bmatrix} -1 & 1 & 1 \\\\ 1 & -2 & 0 \\\\ 1 & 0 & -2 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "    Solving this system of equations, we get:\n",
    "\n",
    "    $$\n",
    "    v_1 = \\begin{bmatrix} -0.816 \\\\ -0.408 \\\\ -0.408 \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "* **For λ₂ = 1:**\n",
    "\n",
    "    Substitute λ₂ into `(CCT - λI)v = 0`:\n",
    "\n",
    "    $$\n",
    "    \\begin{bmatrix} 1 & 1 & 1 \\\\ 1 & 0 & 0 \\\\ 1 & 0 & 0 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "    Solving this system of equations, we get:\n",
    "\n",
    "    $$\n",
    "    v_2 = \\begin{bmatrix} 0 \\\\ -0.707 \\\\ 0.707 \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "* **For λ₃ = 0:**\n",
    "\n",
    "    Substitute λ₃ into `(CCT - λI)v = 0`:\n",
    "\n",
    "    $$\n",
    "    \\begin{bmatrix} 2 & 1 & 1 \\\\ 1 & 1 & 0 \\\\ 1 & 0 & 1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "    Solving this system of equations, we get:\n",
    "\n",
    "    $$\n",
    "    v_3 = \\begin{bmatrix} 0.577 \\\\ -0.577 \\\\ -0.577 \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "**Summary**\n",
    "\n",
    "* Eigenvalues:\n",
    "    $$\n",
    "    \\lambda_1 = 3 \\\\\n",
    "    \\lambda_2 = 1 \\\\\n",
    "    \\lambda_3 = 0\n",
    "    $$\n",
    "* Eigenvectors:\n",
    "    $$\n",
    "    v_1 \\approx \\begin{bmatrix} -0.816 \\\\ -0.408 \\\\ -0.408 \\end{bmatrix} \\\\\n",
    "    v_2 \\approx \\begin{bmatrix} 0 \\\\ -0.707 \\\\ 0.707 \\end{bmatrix} \\\\\n",
    "    v_3 \\approx \\begin{bmatrix} 0.577 \\\\ -0.577 \\\\ -0.577 \\end{bmatrix}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✅ 2-a-2. calculate the eigenvalues and eigenvectors of ( C^T * C )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvalues and Eigenvectors of CTC\n",
    "\n",
    "Given the matrix:\n",
    "\n",
    "```\n",
    "CTC = [[2, 1],\n",
    "       [1, 2]]\n",
    "```\n",
    "\n",
    "**1. Calculate Eigenvalues**\n",
    "\n",
    "The characteristic equation is `det(CTC - λI) = 0`, where `λ` are the eigenvalues and `I` is the identity matrix.\n",
    "\n",
    "$$\n",
    "CTC - \\lambda I = \\begin{bmatrix} 2 - \\lambda & 1 \\\\ 1 & 2 - \\lambda \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The determinant is:\n",
    "\n",
    "$$\n",
    "\\det(CTC - \\lambda I) = (2 - \\lambda)(2 - \\lambda) - (1)(1) = \\lambda^2 - 4\\lambda + 4 - 1 = \\lambda^2 - 4\\lambda + 3\n",
    "$$\n",
    "\n",
    "Setting the determinant to zero:\n",
    "\n",
    "$$\n",
    "\\lambda^2 - 4\\lambda + 3 = 0 \\\\\n",
    "(\\lambda - 3)(\\lambda - 1) = 0\n",
    "$$\n",
    "\n",
    "Thus, the eigenvalues are:\n",
    "\n",
    "$$\n",
    "\\lambda_1 = 3 \\\\\n",
    "\\lambda_2 = 1\n",
    "$$\n",
    "\n",
    "**2. Calculate Eigenvectors**\n",
    "\n",
    "* **For λ₁ = 3:**\n",
    "\n",
    "    Substitute λ₁ into `(CTC - λI)v = 0`:\n",
    "\n",
    "    $$\n",
    "    \\begin{bmatrix} 2 - 3 & 1 \\\\ 1 & 2 - 3 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} \\\\\n",
    "    \\begin{bmatrix} -1 & 1 \\\\ 1 & -1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "    This gives us the equations:\n",
    "\n",
    "    $$\n",
    "    -x + y = 0 \\\\\n",
    "    x - y = 0\n",
    "    $$\n",
    "\n",
    "    Both equations simplify to `x = y`. Let `x = 1`, then `y = 1`. So, the eigenvector is `v₁ = [1, 1]`.\n",
    "\n",
    "    Normalize the eigenvector:\n",
    "\n",
    "    $$\n",
    "    ||v_1|| = \\sqrt{1^2 + 1^2} = \\sqrt{2} \\\\\n",
    "    v_{1,\\text{normalized}} = \\begin{bmatrix} 1/\\sqrt{2} \\\\ 1/\\sqrt{2} \\end{bmatrix} \\approx \\begin{bmatrix} 0.707 \\\\ 0.707 \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "* **For λ₂ = 1:**\n",
    "\n",
    "    Substitute λ₂ into `(CTC - λI)v = 0`:\n",
    "\n",
    "    $$\n",
    "    \\begin{bmatrix} 2 - 1 & 1 \\\\ 1 & 2 - 1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} \\\\\n",
    "    \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "    This gives us the equation:\n",
    "\n",
    "    $$\n",
    "    x + y = 0\n",
    "    $$\n",
    "\n",
    "    Let `x = 1`, then `y = -1`. So, the eigenvector is `v₂ = [1, -1]`.\n",
    "\n",
    "    Normalize the eigenvector:\n",
    "\n",
    "    $$\n",
    "    ||v_2|| = \\sqrt{1^2 + (-1)^2} = \\sqrt{2} \\\\\n",
    "    v_{2,\\text{normalized}} = \\begin{bmatrix} 1/\\sqrt{2} \\\\ -1/\\sqrt{2} \\end{bmatrix} \\approx \\begin{bmatrix} 0.707 \\\\ -0.707 \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "**Summary**\n",
    "\n",
    "* Eigenvalues:\n",
    "    $$\n",
    "    \\lambda_1 = 3 \\\\\n",
    "    \\lambda_2 = 1\n",
    "    $$\n",
    "* Eigenvectors:\n",
    "    $$\n",
    "    v_1 \\approx \\begin{bmatrix} 0.707 \\\\ 0.707 \\end{bmatrix} \\\\\n",
    "    v_2 \\approx \\begin{bmatrix} 0.707 \\\\ -0.707 \\end{bmatrix}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✅ 2-a-3。顯示（ C * C^T ）的前兩個最大特徵值與（ C^​​T * C ）的前兩個最大特徵值相同。\n",
    "* Eigenvalues of $C * C^T$:\n",
    "    $$\n",
    "    \\lambda_1 = 3 \\\\\n",
    "    \\lambda_2 = 1 \\\\\n",
    "    \\lambda_3 = 0\n",
    "    $$\n",
    "\n",
    "* Eigenvalues of $C^T * C$:\n",
    "    $$\n",
    "    \\lambda_1 = 3 \\\\\n",
    "    \\lambda_2 = 1\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1️⃣透過數值推導，我們已經證明了（C * C^T）的前兩個最大特徵值與（C^T * C）的前兩個最大特徵值相同。    \n",
    "對於我們的例子，從計算結果可以看出：\n",
    "- C * C^T 的特徵值（按降序排列）是 3, 1, 0\n",
    "- C^T * C 的特徵值是 3, 1\n",
    "\n",
    "C * C^T 是 3×3 矩陣，有 3 個特徵值，而 C^T * C 是 2×2 矩陣，只有 2 個特徵值。\n",
    "\n",
    "由於矩陣 C 的秩最多為 2（因為它是 3×2 矩陣），所以 C * C^T 的一個特徵值必然為 0。除此之外，兩個矩陣的非零特徵值是完全相同的。\n",
    "\n",
    "因此，證明了 C * C^T 和 C^T * C 的最大兩個特徵值確實相同，分別是 3 和 1。這些值與我們從奇異值計算出的值（σ₁² = 1.732² ≈ 3，σ₂² = 1）一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2️⃣我們用Python再來證明一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest two eigenvalues of C * C^T: [3. 1.]\n",
      "Largest two eigenvalues of C^T * C: [3. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Compute eigenvalues\n",
    "eigvals_CCT = np.linalg.eigvals(CCT)\n",
    "eigvals_CTC = np.linalg.eigvals(CTC)\n",
    "\n",
    "eigvals_CCT_sorted = np.sort(eigvals_CCT)[::-1]\n",
    "eigvals_CTC_sorted = np.sort(eigvals_CTC)[::-1]\n",
    "\n",
    "# Print results\n",
    "print(\"Largest two eigenvalues of C * C^T:\", eigvals_CCT_sorted[:2])\n",
    "print(\"Largest two eigenvalues of C^T * C:\", eigvals_CTC_sorted[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3️⃣第三種方法，我們用理論推導來證明這一點。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD: Singular Value Decomposition\n",
    "\n",
    "A matrix $C$ can be decomposed as:\n",
    "\n",
    "$$\n",
    "C = U \\Sigma V^T\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $U$ is an orthogonal matrix  \n",
    "- $\\Sigma$ is a diagonal matrix, with singular values of $C$ on the diagonal  \n",
    "- $V^T$ is the transpose of $V$, and $V$ is also an orthogonal matrix  \n",
    "\n",
    "## Computing $C C^T$\n",
    "\n",
    "$$\n",
    "C C^T = (U \\Sigma V^T) (V \\Sigma^T U^T)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= U \\Sigma (V^T V) \\Sigma^T U^T\n",
    "$$\n",
    "\n",
    "Since $V$ is an orthogonal matrix, we have $V^T V = I$ (the identity matrix),\n",
    "\n",
    "$$\n",
    "C C^T = U \\Sigma I \\Sigma^T U^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "= U \\Sigma \\Sigma^T U^T\n",
    "$$\n",
    "\n",
    "Since $\\Sigma$ is a diagonal matrix, $\\Sigma \\Sigma^T$ results in a diagonal matrix with squared singular values on the diagonal.\n",
    "\n",
    "## Computing $C^T C$\n",
    "\n",
    "$$\n",
    "C^T C = (V \\Sigma^T U^T) (U \\Sigma V^T)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= V \\Sigma^T (U^T U) \\Sigma V^T\n",
    "$$\n",
    "\n",
    "Since $U$ is an orthogonal matrix, we have $U^T U = I$ (the identity matrix),\n",
    "\n",
    "$$\n",
    "C^T C = V \\Sigma^T I \\Sigma V^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "= V \\Sigma^T \\Sigma V^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "= V (\\Sigma^T \\Sigma) V^T\n",
    "$$\n",
    "\n",
    "## Relationship of Eigenvalues\n",
    "\n",
    "From our calculations, we can see that:\n",
    "\n",
    "- $$ C C^T = U (\\Sigma \\Sigma^T) U^T $$\n",
    "- $$ C^T C = V (\\Sigma^T \\Sigma) V^T $$\n",
    "\n",
    "Since $\\Sigma$ is a diagonal matrix, the nonzero diagonal elements of $\\Sigma \\Sigma^T$ and $\\Sigma^T \\Sigma$ are the same, which are the squares of the singular values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✅ 2-b-1. Compute a rank 1 approximation C_1 to the matrix C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank-1 Approximation C_1:\n",
      " [[0.99921158 0.99921158]\n",
      " [0.49960579 0.49960579]\n",
      " [0.49960579 0.49960579]]\n"
     ]
    }
   ],
   "source": [
    "# Compute rank-1 approximation C_1\n",
    "rank = 1\n",
    "U1 = U[:, :rank]\n",
    "S1 = Sigma[:rank, :rank]\n",
    "VT1 = VT[:rank, :]\n",
    "C1 = U1 @ S1 @ VT1\n",
    "\n",
    "print(\"Rank-1 Approximation C_1:\\n\", C1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算矩陣 C 的秩一近似 C₁\n",
    "\n",
    "根據奇異值分解定理，矩陣 C 的秩一近似 C₁ 可以使用最大奇異值及其對應的奇異向量來計算：\n",
    "\n",
    "$$\n",
    "C_1 = \\sigma_1 \\times u_1 \\times v_1^T\n",
    "$$\n",
    "\n",
    "其中：\n",
    "\n",
    "- $\\sigma_1$ 是最大奇異值（從給定的 Sigma 矩陣中為 1.732）\n",
    "- $u_1$ 是 U 的第一列（對應於最大奇異值）\n",
    "- $v_1^T$ 是 $V^T$ 的第一行\n",
    "\n",
    "從給定的 SVD 分解組件：\n",
    "\n",
    "- $u_1 = \\begin{bmatrix} -0.816 \\\\ -0.408 \\\\ -0.408 \\end{bmatrix}$\n",
    "- $\\sigma_1 = 1.732$\n",
    "- $v_1^T = \\begin{bmatrix} -0.707 & -0.707 \\end{bmatrix}$\n",
    "\n",
    "計算秩一近似：\n",
    "\n",
    "$$\n",
    "C_1 = 1.732 \\times \\begin{bmatrix} -0.816 \\\\ -0.408 \\\\ -0.408 \\end{bmatrix} \\times \\begin{bmatrix} -0.707 & -0.707 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "得到結果：\n",
    "\n",
    "$$\n",
    "C_1 = \\begin{bmatrix} 0.999 & 0.999 \\\\ 0.500 & 0.500 \\\\ 0.500 & 0.500 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "這是原始矩陣 C 的秩一近似。此近似捕捉了數據中的主要模式，同時將維度降低到秩一。\n",
    "\n",
    "近似誤差的 Frobenius 範數（$\\|C - C_1\\|_F$）約為 1.0，表示在此近似中損失的信息量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✅ 2-b-2. What is the Frobenius norm of the error of this approximation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius norm of the error: 1.000000932399249\n"
     ]
    }
   ],
   "source": [
    "# Compute Frobenius norm of the error\n",
    "error_norm = np.linalg.norm(C - C1, 'fro')\n",
    "print(\"Frobenius norm of the error:\", error_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算秩一近似 C₁ 的誤差\n",
    "\n",
    "要計算秩一近似 C₁ 的誤差，我們需要計算原始矩陣 C 與近似矩陣 C₁ 之間差異的 Frobenius 範數。\n",
    "\n",
    "Frobenius 範數定義為矩陣所有元素平方和的平方根：\n",
    "\n",
    "$$\n",
    "\\|E\\|_F = \\sqrt{\\sum_{i}\\sum_{j}|e_{ij}|^2}\n",
    "$$\n",
    "\n",
    "其中 $E = C - C_1$ 是誤差矩陣。\n",
    "\n",
    "從計算結果來看，秩一近似 C₁ 的誤差 Frobenius 範數為：\n",
    "\n",
    "$$\n",
    "\\|C - C_1\\|_F \\approx 1.0000009324\n",
    "$$\n",
    "\n",
    "這個結果非常接近 1.0，這與 SVD 理論是一致的。根據 SVD 理論，當我們使用最大的 k 個奇異值構建近似時，近似誤差的 Frobenius 範數等於被省略的奇異值的平方和的平方根。\n",
    "\n",
    "在這個例子中，我們只使用了最大的奇異值 $\\sigma_1 = 1.732$ 來構建秩一近似，省略了第二個奇異值 $\\sigma_2 = 1.0$。因此，理論上 ( page 65 of the slide vsmodel_2025.pdf )的誤差範數應該等於：\n",
    "\n",
    "$$\n",
    "\\|C - C_1\\|_F = \\sqrt{\\sigma_2^2} = \\sqrt{1^2} = 1.0\n",
    "$$\n",
    "\n",
    "我們的計算結果與理論預測非常接近，確認了我們的秩一近似是正確的，誤差 Frobenius 範數為 1.0。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
